# -*- coding: utf-8 -*-
"""Parkinsons.ipynb

Automatically generated by Colaboratory.


"""

#importing libraries

import pandas as pd
import numpy as np
import os,sys
from sklearn.preprocessing import MinMaxScaler
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score,confusion_matrix,classification_report
import seaborn as sns

#read the data

Park_data = pd.read_csv('parkinsons.data')
Park_data.head()

#about the data set
"""Matrix column entries (attributes):
name - ASCII subject name and recording number
MDVP:Fo(Hz) - Average vocal fundamental frequency
MDVP:Fhi(Hz) - Maximum vocal fundamental frequency
MDVP:Flo(Hz) - Minimum vocal fundamental frequency
MDVP:Jitter(%),MDVP:Jitter(Abs),MDVP:RAP,MDVP:PPQ,Jitter:DDP - Several measures of variation in fundamental frequency
MDVP:Shimmer,MDVP:Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,MDVP:APQ,Shimmer:DDA - Several measures of variation in amplitude
NHR,HNR - Two measures of ratio of noise to tonal components in the voice
status - Health status of the subject (one) - Parkinson's, (zero) - healthy
RPDE,D2 - Two nonlinear dynamical complexity measures
DFA - Signal fractal scaling exponent
spread1,spread2,PPE - Three nonlinear measures of fundamental frequency variation"""



#get features and labels

features = Park_data.loc[:,Park_data.columns!='status'].values[:,1:]
labels = Park_data.loc[:,'status'].values

#get the count of each label (0 and 1 ) in labels

print(labels[labels==1].shape[0], labels[labels==0].shape[0])

#visualising the data


sns.pairplot(Park_data, x_vars='status',y_vars=['MDVP:Fo(Hz)','MDVP:Fhi(Hz)','MDVP:Flo(Hz)','NHR','HNR'])

# scale features betweeen -1 and 1

scaler=MinMaxScaler((-1,1))
x=scaler.fit_transform(features)
y=labels

#split into train and test set

x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2, random_state=1)

#train the model

model=XGBClassifier()
model.fit(x_train,y_train)

#calculate the accuracy

y_pred = model.predict(x_test)
print("accuracy = ", accuracy_score(y_test,y_pred)*100)

#making the confusion matrix

cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot = True)

#classification report

print(classification_report(y_test, y_pred))

